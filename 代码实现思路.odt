实验开始时手上只有评论数据，对应此文件夹底下的三个csv文件。至于为何xls转换成csv格式，
我的理解是xls属于微软自定义格式，存在版权保护，不允许将编码方式改变为uft-8，而python默认的
编码解码格式为utf-8（千万不要去修改python默认的编码方式），所以强制读取xls文件时，会乱码。

1. 分词工作对应cut.py, 实现方式使用jieba.posseg里的函数，将分词结果保存至cut_pos.txt.
   在此过程中，新创立了三个文件夹，分别对应JD数据，KAOLA数据，TMALL数据
2. 特征词提取工作对应feature_extraction.py，实现起来有一定难度，需要熟练运用正则表达式。
   本实验多次使用到了正则表达式。主要就是从cut_pos.txt中提取/n、/v，然后人工筛选，看看
   哪些词能够用作特征词的。
3. 特征词，情感词模式的匹配对应processing.py。同样需要用到正则表达式，提取如/n/a这样的
   模式。外层有个循环 ，因为是三家的数据都要提取嘛， 进入到三个不同的文件夹完成提取工作。
4. score.py 用于写情感值计算函数，需要引用到预定义的词汇情感值，定义内容在global_values.py
5. visualization.py 用来可视化情感值结果
6. main.py 用来调用一些函数。
程序的执行顺序，直接执行main.py就看得到结果。每一步骤的细节就是按照上面的标号进行的。

其他文件：nouns.py是我用来提取所有名词的，utils.py和test_sample.py本来是准备用来实现语法方面
         的分析的，所以都没用。
